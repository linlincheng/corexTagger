{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: \n",
    "# Part I: airline data illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "02-02-2020:18:09:52 [dataProcessor.py:21] Initializating dataProcessor...\n02-02-2020:18:09:52 [dataProcessor.py:43] Selecting text field...\n02-02-2020:18:09:53 [funcs.py:23] running text cleaning...\n02-02-2020:18:18:04 [funcs.py:39] running sparse matrix tranformation...\n02-02-2020:18:18:10 [funcs.py:46] doc_word shape: (41396, 20000)\n"
    }
   ],
   "source": [
    "# import and clean up your text data\n",
    "from hashtagger.dataProcessor import dataProcessor\n",
    "DataProcessor = dataProcessor(data_path='./airline.csv', response_field='content')\n",
    "DataProcessor.get_text_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pickle\n",
    "pickle_dict = {\n",
    "    \"vocabulary\" : DataProcessor.vocabulary, \n",
    "    \"doc_words\" : DataProcessor.doc_words\n",
    "}\n",
    "pickle.dump(pickle_dict, open(\"tmp.pkl\", 'wb'), protocol=-1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pickle\n",
    "DataProcessor = pickle.load(open(\"tmp.pkl\", 'rb'))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "02-02-2020:18:58:08 [modelTrainer.py:74] Initializing unSupervisedTrainer class...\n02-02-2020:18:58:08 [modelTrainer.py:83] Running model training...\n02-02-2020:19:01:17 [modelTrainer.py:43] Printing topic words: \n02-02-2020:19:01:18 [modelTrainer.py:61] Saving model objects...\n0: class,business,food,economy,good,lounge,flat,entertainment,selection,movie\n1: minute,arrive,wait,late,gate,airport,leave,board,min,departure\n2: hour,day,hotel,finally,later,miss,voucher,connect,eventually,night\n3: sydney,singapore,qantas,melbourne,kong,hong,china,emirate,bangkok,shanghai\n4: tell,delay,cancel,customer,home,weather,vega,email,explanation,refund\n5: drink,snack,coffee,sandwich,juice,offer,tea,cheese,hot,soft\n6: seat,recline,leg,row,room,uncomfortable,aisle,window,space,narrow\n7: meal,cabin,serve,crew,ife,breakfast,wine,dinner,chicken,aircraft\n8: check,bag,online,luggage,boarding,line,counter,pas,ticket,agent\n9: water,toilet,blanket,galley,pillow,work,glass,light,cold,bottle\n10: security,terminal,queue,english,checkin,immigration,announcement,staff,speak,transfer\n11: say,people,just,make,try,come,dont,want,bad,didnt\n12: long,haul,ba,star,alliance,carrier,standard,route,look,really\n13: passenger,ask,sit,child,plane,walk,away,close,door,attendant\n14: cost,baggage,low,weight,ryanair,price,allowance,card,hand,rule\n15: pay,book,extra,change,know,way,money,travel,advance,worth\n16: friendly,comfortable,clean,excellent,efficient,professional,helpful,rude,pleasant,quick\n17: like,im,use,think,need,ive,point,id,feel,sure\n18: canada,rouge,toronto,air,los,angeles,ac,westjet,vancouver,transat\n19: review,read,year,fly,experience,frequent,flyer,airway,trip,past\n"
    }
   ],
   "source": [
    "# train unsupervised version for anchor words inspirations\n",
    "from hashtagger.modelTrainer import unSupervisedTrainer\n",
    "unSupervisedTrainer = unSupervisedTrainer(words=DataProcessor.vocabulary,doc_words=DataProcessor.doc_words, n_topic=20, save_model=True, model_directory='model/', print_words=True)\n",
    "unSupervisedTrainer.train_model()\n",
    "unSupervisedTrainer.save_model_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "02-02-2020:19:01:19 [modelTrainer.py:101] Initializing semiSupervisedTrainer class\n02-02-2020:19:01:19 [modelTrainer.py:111] Running model training...\n02-02-2020:19:03:41 [modelTrainer.py:43] Printing topic words: \n02-02-2020:19:03:42 [modelTrainer.py:61] Saving model objects...\n0: meal,serve,breakfast,hot,dinner,vegetarian,hungry,preordered,gluten,veg\n1: business,lounge,bed,class,flat,lie,access,upgrade,champagne,shower\n2: seat,recline,uncomfortable,row,pitch,leg,aisle,narrow,window,space\n3: screen,tv,movie,touch,watch,personal,individual,music,video,channel\n4: delay,weather,explanation,snow,slight,atc,hrs,1hr,informed,2hrs\n5: luggage,hand,piece,suitcase,retrieve,conveyor,oversized,handbag,restriction,lost\n6: drink,chicken,sandwich,coffee,juice,snack,offer,cheese,tea,salad\n7: food,good,entertainment,economy,ife,selection,choice,service,a380,sleep\n8: check,gate,bag,line,agent,counter,pas,ticket,desk,print\n9: hour,wait,arrive,late,leave,minute,finally,hotel,later,miss\n10: book,day,airport,email,change,phone,online,send,receive,website\n11: passenger,ask,sit,child,start,walk,overhead,allow,close,door\n12: board,boarding,security,terminal,checkin,queue,arrival,departure,bus,immigration\n13: crew,cabin,friendly,comfortable,clean,excellent,efficient,attentive,aircraft,professional\n14: pay,cost,extra,charge,price,fee,low,fare,cheap,worth\n15: 2014,2013,june,july,2015,april,march,jan,feb,august\n16: tell,cancel,customer,canada,home,rouge,toronto,rude,refund,bad\n17: toilet,tray,water,abu,dhabi,blanket,work,galley,table,dirty\n18: say,people,make,know,just,didnt,come,dont,try,want\n19: airline,fly,like,review,use,year,read,think,im,experience\n02-02-2020:19:03:42 [modelTrainer.py:128] Saving copy of anchor words...\n"
    }
   ],
   "source": [
    "# start building up your anchor words, try out Semisupervised version \n",
    "# with anchor_words (your domain expertise) injections;\n",
    "# Take printed outputs, edit your anchor_words.json, and repeat the first step\n",
    "from hashtagger.modelTrainer import semiSupervisedTrainer\n",
    "SemiSupervisedTrainer = semiSupervisedTrainer(words=DataProcessor.vocabulary,doc_words=DataProcessor.doc_words, n_topic=20, save_model=True, model_directory='model/', print_words=True, anchor_path='./anchor_words.json')\n",
    "SemiSupervisedTrainer.train_model()\n",
    "SemiSupervisedTrainer.save_model_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo\n",
    "# Part II: test_data (smaller dataset) illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "02-02-2020:21:19:06 [dataProcessor.py:21] Initializating dataProcessor...\n02-02-2020:21:19:06 [dataProcessor.py:43] Selecting text field...\n02-02-2020:21:19:06 [funcs.py:23] running text cleaning...\n02-02-2020:21:19:06 [funcs.py:39] running sparse matrix tranformation...\n02-02-2020:21:19:06 [funcs.py:46] doc_word shape: (3, 7)\n02-02-2020:21:19:06 [modelTrainer.py:74] Initializing unSupervisedTrainer class...\n02-02-2020:21:19:06 [modelTrainer.py:83] Running model training...\n02-02-2020:21:19:06 [modelTrainer.py:43] Printing topic words: \n02-02-2020:21:19:06 [modelTrainer.py:61] Saving model objects...\n0: dog,rabbit,train\n1: car,flight,cat\n2: catch\n"
    }
   ],
   "source": [
    "# see first proposed topic: dog, rabbit, train; second topic: car, flight, cat ; \n",
    "# --> some consistency, but somehow mixed up\n",
    "from hashtagger.dataProcessor import dataProcessor\n",
    "DataProcessor = dataProcessor(data_path='./test/test_data.csv', response_field='content')\n",
    "DataProcessor.get_text_data()\n",
    "\n",
    "from hashtagger.modelTrainer import unSupervisedTrainer\n",
    "unSupervisedTrainer = unSupervisedTrainer(words=DataProcessor.vocabulary,doc_words=DataProcessor.doc_words, n_topic=3, save_model=True, model_directory='./test/model/', print_words=True)\n",
    "unSupervisedTrainer.train_model()\n",
    "unSupervisedTrainer.save_model_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "02-02-2020:15:57:18 [dataProcessor.py:21] Initializating dataProcessor...\n02-02-2020:15:57:18 [dataProcessor.py:43] Selecting text field...\n02-02-2020:15:57:18 [funcs.py:23] running text cleaning...\n02-02-2020:15:57:18 [funcs.py:39] running sparse matrix tranformation...\n02-02-2020:15:57:18 [funcs.py:46] doc_word shape: (3, 7)\n02-02-2020:15:57:18 [modelTrainer.py:101] Initializing semiSupervisedTrainer class\n02-02-2020:15:57:18 [modelTrainer.py:111] Running model training...\n02-02-2020:15:57:19 [modelTrainer.py:43] Printing topic words: \n02-02-2020:15:57:19 [modelTrainer.py:61] Saving model objects...\n02-02-2020:15:57:19 [modelTrainer.py:128] Saving copy of anchor words...\n0: dog,rabbit,cat\n1: car,flight,train\n2: catch\n"
    }
   ],
   "source": [
    "# with anchor_words set up(in test dir), new output:\n",
    "# 0: dog,rabbit,cat\n",
    "# 1: car,flight,train\n",
    "# 2: catch\n",
    "# much more consistent\n",
    "from hashtagger.dataProcessor import dataProcessor\n",
    "from hashtagger.modelTrainer import semiSupervisedTrainer\n",
    "\n",
    "DataProcessor = dataProcessor(data_path='./test/test_data.csv', response_field='content')\n",
    "DataProcessor.get_text_data()\n",
    "\n",
    "SemiSupervisedTrainer = semiSupervisedTrainer(\n",
    "    words=DataProcessor.vocabulary,\n",
    "    doc_words=DataProcessor.doc_words,\n",
    "    n_topic=3,\n",
    "    save_model=True,\n",
    "    model_directory='test/model/',\n",
    "    print_words=True,\n",
    "    anchor_path='./test/test_anchor_words.json')\n",
    "SemiSupervisedTrainer.train_model()\n",
    "SemiSupervisedTrainer.save_model_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "02-02-2020:21:25:51 [funcs.py:23] running text cleaning...\n02-02-2020:21:25:51 [funcs.py:39] running sparse matrix tranformation...\n02-02-2020:21:25:51 [funcs.py:46] doc_word shape: (1, 7)\n"
    },
    {
     "data": {
      "text/plain": "[['animals']]"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hashtagger.modelPredictor import modelPredictor\n",
    "ModelPredictor = modelPredictor(text_data = 'cat and dogs', model_directory='./test/load_model/')\n",
    "predicted_tags = ModelPredictor.predict_tags()\n",
    "predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}